---
title: "Algorithm Evaluation"
author: "Ivan Timothy Halim"
date: "12/3/2020"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(here)
library(scales)
library(rBayesianOptimization)
library(pso)
devtools::load_all()

nyse <- readRDS(here("results", "nyse_prices.rds"))
securities <- readRDS(here("results", "nyse_securities.rds"))
mean_stock <- readRDS(here("results", "nyse_mean_returns.rds"))
rf <- readRDS(here("results", "risk_free_rate.rds"))
nyse_cov <- readRDS(here("results", "nyse_covariance.rds"))
sharpe_ratio <- readRDS(here("results", "sharpe_ratio_fn.rds"))
```

## Define Parameters

Let's define the search boundary

```{r}
lower <- rep(0, 3)
upper <- rep(1, 3)
```

Let's set the initial sample

```{r}
set.seed(123)
search_grid <- as.matrix(
                  data.frame(
                    w1 = runif(20,0,1),
                    w2 = runif(20,0,1),
                    w3 = runif(20,0,1)
                  )
                )

head(search_grid)
```

## Run the Algorithm

Let's run the algorithm `bayesian_optimization()` that we implemented. The parameters include:

* `FUN`: the fitness function
* `lower`: the lower bounds of each variables
* `upper`: the upper bounds of each variables
* `init_grid_dt`: user specified points to sample the target function
* `init_points`: Number of randomly chosen points to sample the target function before Bayesian Optimization fitting the Gaussian Process
* `n_iter`: number of repeated Bayesian Optimization
* `xi`: tunable parameter ![equation](https://latex.codecogs.com/gif.latex?%5Cxi) of Expected Improvement, to balance exploitation against exploration, increasing `xi` will make the optimized hyper parameters more spread out across the whole range
* `noise`: represents the amount of noise in the training data
* `max`: specifies whether we're maximizing or minimizing a function
* `acq`: choice of acquisition function (Expected Improvement by default)

```{r}
(bayes_finance <- bayesian_optimization(FUN=sharpe_ratio, lower=lower, upper=upper,
                                        init_grid_dt=search_grid))
```

Result of the function consists of a list with 2 components:

* par: a vector of the best hyperparameter set found
* value: the value of metrics achieved by the best hyperparameter set

So, what is the optimum Sharpe Ratio from Bayesian optimization?

```{r}
bayes_finance$value
```

The greater a portfolio's Sharpe ratio, the better its risk-adjusted performance. If the analysis results in a negative Sharpe ratio, it either means the risk-free rate is greater than the portfolio's return, or the portfolio's return is expected to be negative.

Let's check the total weight of the optimum result.

```{r}
sum(bayes_finance$par)
```
Our weights violate the constraint, which is probably the reason why our Sharpe's Ratio is negative. More work can be done to improve sampling for next ![equation](https://latex.codecogs.com/gif.latex?x) as well as finding the optimum value for parameters ![equation](https://latex.codecogs.com/gif.latex?l) and ![equation](https://latex.codecogs.com/gif.latex?%5Csigma_f). 

Based on Bayesian Optimization, here is how your asset should be distributed.

```{r}
(bayes_result <- data.frame(stock = unique(nyse$symbol),
                            weight = bayes_finance$par) %>%
                  arrange(desc(weight)) %>%
                  mutate(weight = percent(weight, accuracy = 0.01)) %>%
                  left_join(securities, by = "stock") %>%
                  select(stock, Security, everything()))
```

## `rBayesianOptimization` Package

Let's compare our result to the one obtained using `rBayesianOptimization` package.

We need to redefine the fitness function to suit the `BayesianOptimization` function from `rBayesianOptimization` package.

```{r}
fitness <- function(w1, w2, w3) {
    # Assign weight for each stocks
    weight_stock <- c(w1, w2, w3)
    
    # Calculate the numerator
    f1 <- weight_stock * mean_stock$mean
    
    # Calculate the denominator
    f2 <- rowSums(outer(weight_stock, weight_stock) * nyse_cov)
    
    # Calculate Fitness Value
    fitness <- (sum(f1) - rf)/sum(f2)
    
    # Penalize Constraint Violation
    fitness <- fitness - 1e9 * (round(sum(weight_stock), 10) - 1)^2
    
    result <- list(Score = fitness, Pred = 0)
    return(result)
}
```

```{r}
search_bound <- list(w1 = c(0,1), w2 = c(0,1),
                     w3 = c(0,1))
search_grid_df <- data.frame(search_grid)

set.seed(1)
rbayes_finance <- BayesianOptimization(FUN = fitness, bounds = search_bound, 
                     init_grid_dt = search_grid_df, n_iter = 10, acq = "ei")
```

The solution has a Sharpe Ratio of `r round(rbayes_finance$Best_Value[1], 4)` with the following weight.

```{r}
(rbayes_result <- data.frame(stock = unique(nyse$symbol),
                             weight = rbayes_finance$Best_Par) %>%
                  arrange(desc(weight)) %>%
                  mutate(weight = percent(weight, accuracy = 0.01)) %>%
                  left_join(securities, by = "stock") %>%
                  select(stock, Security, everything()))
```

The solution has a higher Sharpe ratio than our implementation. Both implementations agree that ULTA is the most profitable asset.

## Particle Swarm Optimization

Let's compare the optimum Sharpe ratio from Bayesian Optimization with another algorithm: Particle Swarm Optimization.

We need to redefine the fitness function to suit the PSO from `pso` package.

```{r}
fitness <- function(x){
  # Assign weight for each stocks
  weight_stock <- numeric()
  for (i in 1:n_distinct(nyse$symbol)) {
    weight_stock[i] <- x[i]
  }
  
 # Calculate the numerator
 f1 <- numeric()
 for (i in 1:n_distinct(nyse$symbol)) {
   f1[i] <- weight_stock[i]*mean_stock$mean[i]
 }
   
 # Calculate the denominator
 f2 <- numeric()
 for (i in 1:n_distinct(nyse$symbol)) {
   f3 <- numeric()
   
   for (j in 1:n_distinct(nyse$symbol)) {
    f3[j] <- weight_stock[i]*weight_stock[j]*nyse_cov[i,j]
   }
   
 f2[i] <- sum(f3)
 }

  # Calculate Fitness Value
 fitness <- (sum(f1)-rf)/sum(f2)

 # Penalize Constraint Violation
 fitness <- fitness - 1e9 * (round(sum(weight_stock),10)-1)^2
 
 return(fitness)
}
```

Letâ€™s run the PSO Algorithm. PSO will run for 10,000 iterations with swarm size of 100. If in 500 iterations there is no improvement on the fitness value, the algorithm will stop.

```{r}
set.seed(123)
pso_finance <- psoptim(par = rep(NA,3), fn = function(x){-fitness(x)}, 
        lower = rep(0,3), upper = rep(1,3), 
        control = list(maxit = 10000, s = 100, maxit.stagnate = 500))
```

```{r}
pso_finance
```

The solution has a Sharpe Ratio of `r round(-pso_finance$value, 4)`.

Let's check the total weight

```{r}
sum(pso_finance$par)
```

Based on PSO, here is how your asset should be distributed.

```{r}
(pso_result <- data.frame(stock = unique(nyse$symbol),
                          weight = pso_finance$par) %>% 
                arrange(desc(weight)) %>% 
                mutate(weight = percent(weight, accuracy = 0.01)) %>% 
                left_join(securities, by = "stock") %>% 
                select(stock, Security, everything()))
```

For this problem, PSO works better than Bayesian Optimization, indicated by the optimum fitness value. However, we only ran 30 function evalutions (20 from samples, 10 from iterations) with Bayesian Optimization, compared to PSO, which run more than 1000 evaluations. The trade-off is Bayesian Optimization ran slower than PSO, since the function evaluation is cheap.

## Normalization

We could also normalize our search grid to ensure that the weights don't add up to more than 1, therefore not violating the constraint.

```{r}
search_grid <- normalize(search_grid)
(bayes_finance_norm <- bayesian_optimization(FUN=sharpe_ratio, lower=lower, upper=upper,
                                        init_grid_dt=search_grid))
```
The solution has a Sharpe Ratio of `r round(bayes_finance_norm$value, 4)`. We achieve a higher performance than both `rBayesianOptimization` and Particle Swarm Optimization!

Based on normalized Bayes, here is how your asset should be distributed.

```{r}
(bayes_norm_result <- data.frame(stock = unique(nyse$symbol),
                                 weight = bayes_finance_norm$par) %>%
                  arrange(desc(weight)) %>%
                  mutate(weight = percent(weight, accuracy = 0.01)) %>%
                  left_join(securities, by = "stock") %>%
                  select(stock, Security, everything()))
```

## Pushing the limit

Our implementation uses QR decomposition to find the least squares approximation to avoid having to compute the inverse of a close to singular matrix. This means that our implementation is numerically more stable but it is also tolerant to slight fluctuations in the fitness value. Suppose we want to make it stricter by using the naive implementation, but at the cost of being less stable.

```{r}
(bayes_finance_naive <- bayesian_optimization(FUN=sharpe_ratio, lower=lower, upper=upper,
                                        init_grid_dt=search_grid, n_iter=1, naive=TRUE))
```

The solution has a Sharpe Ratio of `r round(bayes_finance_naive$value, 4)` which is even higher than the previous one! However, keep in mind that this only works after setting `n_iter` to just 1 iteration.

Based on the all-normalized Bayes, here is how your asset should be distributed.

```{r}
(bayes_naive_result <- data.frame(stock = unique(nyse$symbol),
                                 weight = bayes_finance_naive$par) %>%
                  arrange(desc(weight)) %>%
                  mutate(weight = percent(weight, accuracy = 0.01)) %>%
                  left_join(securities, by = "stock") %>%
                  select(stock, Security, everything()))
```

```{r}
write_csv(bayes_result, here("results", "bayes_result.csv"))
write_csv(rbayes_result, here("results", "rbayes_result.csv"))
write_csv(pso_result, here("results", "pso_result.csv"))
write_csv(bayes_norm_result, here("results", "bayes_norm_result.csv"))
write_csv(bayes_naive_result, here("results", "bayes_naive_result.csv"))
```